{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/Users/HangYao/anaconda/lib/python27.zip', '/Users/HangYao/anaconda/lib/python2.7', '/Users/HangYao/anaconda/lib/python2.7/plat-darwin', '/Users/HangYao/anaconda/lib/python2.7/plat-mac', '/Users/HangYao/anaconda/lib/python2.7/plat-mac/lib-scriptpackages', '/Users/HangYao/anaconda/lib/python2.7/lib-tk', '/Users/HangYao/anaconda/lib/python2.7/lib-old', '/Users/HangYao/anaconda/lib/python2.7/lib-dynload', '/Users/HangYao/anaconda/lib/python2.7/site-packages/Sphinx-1.4.1-py2.7.egg', '/Users/HangYao/anaconda/lib/python2.7/site-packages/setuptools-23.0.0-py2.7.egg', '/Users/HangYao/anaconda/lib/python2.7/site-packages', '/Users/HangYao/anaconda/lib/python2.7/site-packages/aeosa']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path = ['', '/Users/HangYao/anaconda/lib/python27.zip', '/Users/HangYao/anaconda/lib/python2.7', \n",
    "            '/Users/HangYao/anaconda/lib/python2.7/plat-darwin', '/Users/HangYao/anaconda/lib/python2.7/plat-mac', \n",
    "            '/Users/HangYao/anaconda/lib/python2.7/plat-mac/lib-scriptpackages', \n",
    "            '/Users/HangYao/anaconda/lib/python2.7/lib-tk', '/Users/HangYao/anaconda/lib/python2.7/lib-old', \n",
    "            '/Users/HangYao/anaconda/lib/python2.7/lib-dynload', \n",
    "            '/Users/HangYao/anaconda/lib/python2.7/site-packages/Sphinx-1.4.1-py2.7.egg', \n",
    "            '/Users/HangYao/anaconda/lib/python2.7/site-packages/setuptools-23.0.0-py2.7.egg', \n",
    "            '/Users/HangYao/anaconda/lib/python2.7/site-packages', \n",
    "            '/Users/HangYao/anaconda/lib/python2.7/site-packages/aeosa']\n",
    "print sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from math import sqrt\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HangYao/anaconda/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/HangYao/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data for Cleaning & Modeling.csv\")\n",
    "train_num = data.shape[0]\n",
    "data2 = pd.read_csv(\"Holdout for Testing.csv\")\n",
    "\n",
    "# Concat training and test data\n",
    "data = pd.concat([data, data2], axis=0)\n",
    "\n",
    "# Drop the data instance with all NaN values at #364111\n",
    "index = data['X11'].index[data['X11'].apply(pd.isnull)]\n",
    "data.drop(index, axis=0, inplace=True)\n",
    "#pd.set_option(\"display.max_columns\",50)\n",
    "\n",
    "# Convert % and $ data to float\n",
    "data[['X1','X4','X5','X6','X30']] = data[['X1','X4','X5','X6','X30']].replace('[$,%]','',regex=True).astype(float)\n",
    "\n",
    "# Convert X7 to boolean\n",
    "data['X7'] = data['X7'].replace([' 36 months', ' 60 months'], [0, 1]).astype('bool')\n",
    "\n",
    "# Create Dummies for X8\n",
    "data['X8'].fillna('OTHER', inplace=True)\n",
    "data_X8 = pd.get_dummies(data['X8'], prefix='X8', drop_first=True).astype('bool')\n",
    "\n",
    "# Convert X11 to int\n",
    "data['X11'] = data['X11'].map({'< 1 year': 0, '1 year': 1, '2 years': 2,\n",
    "                               '3 years': 3, '4 years': 4, '5 years': 5,\n",
    "                               '6 years': 6, '7 years': 7, '8 years': 8,\n",
    "                               '9 years': 9, '10+ years': 10, 'n/a': 0}).astype(float)\n",
    "\n",
    "# Create Dummies for X12\n",
    "data['X12'].fillna('OTHER', inplace=True)\n",
    "data_X12 = pd.get_dummies(data['X12'], prefix='X12', drop_first=True).astype('bool')\n",
    "\n",
    "# Fill NaN in X13 with the median\n",
    "data['X13'].fillna(data['X13'].median(), inplace=True)\n",
    "\n",
    "# Create Dummies for X14\n",
    "data['X14'] = data['X14'].replace(['NONE', 'ANY'], ['OTHER', 'OTHER'])\n",
    "data['X14'] = data['X14'].replace(['not verified','VERIFIED - income source','VERIFIED - income'], ['NV','VIS','VI'])\n",
    "data_X14 = pd.get_dummies(data['X14'], prefix='X14', drop_first=True).astype('bool')\n",
    "\n",
    "# Create Dummies for X17\n",
    "data_X17 = pd.get_dummies(data['X17'], prefix='X17', drop_first=True).astype('bool')\n",
    "\n",
    "# Create Dummies for X25, X26\n",
    "data['X25'].loc[data['X25'] > 0] = 'NONZERO'\n",
    "data['X25'].loc[data['X25'] == 0] = 'ZERO'\n",
    "data['X25'].fillna('NA', inplace=True)\n",
    "data_X25 = pd.get_dummies(data['X25'], prefix='X25', drop_first=True).astype('bool')\n",
    "data['X26'].loc[data['X26'] > 0] = 'NONZERO'\n",
    "data['X26'].loc[data['X26'] == 0] = 'ZERO'\n",
    "data['X26'].fillna('NA', inplace=True)\n",
    "data_X26 = pd.get_dummies(data['X26'], prefix='X26', drop_first=True).astype('bool')\n",
    "\n",
    "# Fill NaN of X30 with 0\n",
    "data['X30'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert X32 to boolean\n",
    "data['X32'] = data['X32'].replace(['f', 'w'], [0, 1]).astype('bool')\n",
    "\n",
    "# Drop unused columns\n",
    "data.drop(['X2','X3','X8','X9','X10','X12','X14','X15','X16','X17','X18','X19','X20','X23','X25','X26'],\n",
    "          axis=1, inplace=True)\n",
    "\n",
    "# Concat Dummies\n",
    "data = pd.concat([data, data_X8, data_X12, data_X14, data_X17, data_X25, data_X26], axis=1)\n",
    "\n",
    "y = data['X1']\n",
    "data.drop('X1', axis=1, inplace=True)\n",
    "\n",
    "# Scale data columns with float dtypes\n",
    "scaler = StandardScaler()\n",
    "data_float = data.select_dtypes(include=['float64'])\n",
    "data[data_float.columns] = pd.DataFrame(scaler.fit_transform(data_float), columns=data_float.columns)\n",
    "\n",
    "# Split test_data\n",
    "X_test = data[train_num-1:]\n",
    "data_all = data[:train_num-1]\n",
    "labels_all = y[:train_num-1]\n",
    "\n",
    "# Drop all data instances with missing labels X1\n",
    "data_all = data_all[pd.notnull(labels_all)].reset_index(drop=True)\n",
    "labels_all = labels_all[pd.notnull(labels_all)].reset_index(drop=True)\n",
    "\n",
    "# Split train_data, valid_data\n",
    "train_index, valid_index = next(iter(ShuffleSplit(labels_all.shape[0],test_size=0.2,random_state=seed)))\n",
    "X_train, X_valid = np.array(data_all)[train_index,:], np.array(data_all)[valid_index,:]\n",
    "y_train, y_valid = np.array(labels_all)[train_index], np.array(labels_all)[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print \"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    clf.fit(X_train, y_train)\n",
    "    print \"RMSE score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"RMSE score for validation set: {:.4f}.\".format(predict_labels(clf, X_test, y_test))\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    y_pred = clf.predict(features)\n",
    "    return sqrt(mean_squared_error(target, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "clf_A = ExtraTreesRegressor(random_state=seed)\n",
    "clf_B = RandomForestRegressor(random_state=seed)\n",
    "clf_C = GradientBoostingRegressor(random_state=seed)\n",
    "clf_D = RidgeCV()\n",
    "clf_E = LassoCV(random_state=seed)\n",
    "clf_F = ElasticNetCV(random_state=seed)\n",
    "\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D, clf_E, clf_F]:\n",
    "    train_predict(clf, X_train, y_train, X_valid, y_valid)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=4)]: Done 135 out of 135 | elapsed: 57.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'warm_start': True, 'oob_score': False, 'n_jobs': 1, 'verbose': 0, 'max_leaf_nodes': None, 'bootstrap': True, 'min_samples_leaf': 3, 'n_estimators': 20, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'criterion': 'mse', 'random_state': 42, 'max_features': 'auto', 'max_depth': None} \n",
      "\n",
      "Tuned model has a training RMSE score of 0.9121.\n",
      "Tuned model has a testing RMSE score of 1.6725.\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "parameters = {'n_estimators':(10,15,20),\n",
    "              'min_samples_split':(2,3,4),\n",
    "              'min_samples_leaf':(1,2,3)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=seed, warm_start=True)\n",
    "score = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "grid_obj = GridSearchCV(rfr, param_grid=parameters, scoring=score, verbose=1, n_jobs=4, cv=5)\n",
    "grid_obj= grid_obj.fit(X_train, y_train)\n",
    "rfr = grid_obj.best_estimator_\n",
    "print rfr.get_params(), '\\n'\n",
    "print \"Tuned model has a training RMSE score of {:.4f}.\".format(predict_labels(rfr, X_train, y_train))\n",
    "print \"Tuned model has a testing RMSE score of {:.4f}.\".format(predict_labels(rfr, X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normalize': False, 'alphas': (1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0), 'fit_intercept': True, 'gcv_mode': None, 'store_cv_values': False, 'scoring': None, 'cv': 5} \n",
      "\n",
      "Tuned model has a training RMSE score of 1.9168.\n",
      "Tuned model has a testing RMSE score of 1.9089.\n"
     ]
    }
   ],
   "source": [
    "# RidgeCV\n",
    "ridge = RidgeCV(alphas=(1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1.0, 10.0), cv=5)\n",
    "ridge = ridge.fit(X_train, y_train)\n",
    "print ridge.get_params(), '\\n'\n",
    "print \"Tuned model has a training RMSE score of {:.4f}.\".format(predict_labels(ridge, X_train, y_train))\n",
    "print \"Tuned model has a testing RMSE score of {:.4f}.\".format(predict_labels(ridge, X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save regressors\n",
    "pickle_file = 'regressor.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'random_forest_regressor': rfr,\n",
    "    'ridge': ridge,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load regressor\n",
    "pickle_file = 'regressor.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  rfr = save['random_forest_regressor']\n",
    "  ridge = save['ridge']\n",
    "  del save\n",
    "\n",
    "# Predict test_data\n",
    "y_pred_rfr = rfr.predict(X_test)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "pd.DataFrame({'X1_Random_Forest': y_pred_rfr, 'X1_Ridge': y_pred_ridge}).to_csv('Results from Hang Yao.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
